{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2171b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c69abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_url = \"https://tfhub.dev/tensorflow/movinet/a0/base/kinetics-600/classification/3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "217dac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = hub.KerasLayer(hub_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6653e136",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasLayer' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fa594873e250>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasLayer' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "x =  encoder.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e5c943b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 600) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e3b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(\n",
    "    shape=[None, 172, 172, 3],\n",
    "    dtype=tf.float32,\n",
    "    name='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712e03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [batch_size, 600]\n",
    "outputs = encoder(dict(image=inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7cda1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs, outputs, name='movinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2628f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"movinet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, None, 172, 172, 3 0         \n",
      "_________________________________________________________________\n",
      "keras_layer (KerasLayer)     (None, 600)               3126071   \n",
      "=================================================================\n",
      "Total params: 3,126,071\n",
      "Trainable params: 3,111,799\n",
      "Non-trainable params: 14,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436946d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, max_frames=0, resize=(172, 172)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            #frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "            \n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        \n",
    "    return np.array(frames) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde79dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_path = os.path.join('Train_Data','1_Finger_Click','Video_Test_4 (2).mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d80d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_video = load_video( video_file_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11a9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ade0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = np.reshape(sample_video , [1, 60, 172, 172, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b310282",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b8a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e4f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f71bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict( input_video )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00894373",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540efee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec68fac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF.2.5.0-GPU",
   "language": "python",
   "name": "tf.2.5.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
